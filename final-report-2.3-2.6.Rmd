---
title: "STATS 415 Final Project"
author: "Margot Douillet, Richard Einhorn, Nathan Nguyen, Edmund Tian"
date: "12/4/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
set.seed(42)
```

This report presents our analysis and findings from building various models for the prediction task.

# 2.3 Linear Regression
```{r}
final_project <- read_csv("data/final_project-1.csv")
# Removing the index column
final_project <- final_project %>% select(Asset_1:Asset_3)
Asset_1 <- final_project %>% select(Asset_1)
df <- read.csv("output/bret.csv")
Asset_1_lead <- lead(Asset_1, n=10, default=tail(Asset_1, 1))
Asset_1_HRet_10 <- (Asset_1_lead - Asset_1) / Asset_1
colnames(Asset_1_HRet_10) <- c("Asset_1_HRet_10")
df <- cbind(df, Asset_1_HRet_10)

train_size <- floor(nrow(df) * 0.7)
test_size <- nrow(df) - train_size

train_set <- head(df, train_size)
test_set <- tail(df, test_size)

lr_modl <- lm(Asset_1_HRet_10 ~ ., data=train_set)
summary(lr_modl)
```

It seems that the 3, 10, and 30 minutes backward returns of Asset 2 and the 3 minutes backward return of Asset 3 are important in predicting the forward return of Asset 1.

```{r}
train_pred <- predict.lm(lr_modl, train_set)
test_pred <- predict.lm(lr_modl, test_set)

# In-sample correlation
cor(as.matrix(cbind(train_pred, train_set$Asset_1_HRet_10)))
sprintf("The in-sample correlation is %s", 
        cor(as.matrix(cbind(train_pred, train_set$Asset_1_HRet_10)))[[2,1]])
# Out-sample correlation
cor(as.matrix(cbind(test_pred, test_set$Asset_1_HRet_10)))
sprintf("The out-sample correlation is %s",
        cor(as.matrix(cbind(test_pred, test_set$Asset_1_HRet_10)))[[2,1]])

train_pred <- data.frame(train_pred)
test_pred <- data.frame(test_pred)
colnames(train_pred) <- c("Asset_1_HRet_10_pred")
colnames(test_pred) <- c("Asset_1_HRet_10_pred")
Asset_1_HRet_10_lead <- rbind(train_pred, test_pred)
df <- cbind(df, Asset_1_HRet_10_lead)

# 3 Weeks Rolling correlation
for (i in 1:nrow(df)) {
  start = max(i - 30240, 1)
  df$Rho[i] = cor(df$Asset_1_HRet_10[start:i], df$Asset_1_HRet_10_pred[start:i])
}
plot(df$Rho, xlab="Time", ylab="Correlation", 
     main="3 Weeks Rolling correlation between true and pred")
```

This correlation structure is unstable near the beginning of the year but is relatively stationary for the year. There are some fluctuations but the correlation seem to stay between 0 and 0.1.

# 2.4 KNN Regression

## Helper Functions
```{r}
# h-min backward return
h_min_br <- function(df, h){
  data <- df
  a <- h + 2
  c <- h + 1
  data[a:nrow(data),] <- data[2:(nrow(data)-h),]
  data[1:c,] <- data[2,]
  data <- (df - data)/(data)
}

# h-min forward return
h_min_f <- function(df, h){
  data <- df
  a <- (nrow(df) - h)
  b <- h + 1
  c <- a + 1
  d <- nrow(df)
  data[c:d,] <- data[d,]
  data[1:a,] <- data[b:d,]
  data <- (data - df)/df
}
```

## Creating Predictors, Testing and Training data
```{r}
# Response vector
rf_t10 <- h_min_f(final_project, 10)[,1]
# Predictors
# Using the h-min backward return from part 2.1
rb_t3 <- h_min_br(final_project, 3)[,1]
rb_t10 <- h_min_br(final_project, 10)[,1]
rb_t30 <- h_min_br(final_project, 30)[,1]
rb_df <- data.frame(rf_t10, rb_t3, rb_t10, rb_t30)
# Splitting the dataframe into training and testing
Train_rb <- rb_df[1:366912,]
Test_rb <- rb_df[366913:524160,]
```

## KNN Regression
```{r}
library(FNN)
# The different K-values to be used
K <- c(5,25,125,625,1000)
# Finding the test MSE for each K
testMSE <- c()
for(i in 1:length(K)){
  est <- knn.reg(train = Train_rb[,2:4], test = Test_rb[2:4], y = Train_rb$rf_t10, k = K[i])
  testMSE[i] <- mean((est$pred - Test_rb$rf_t10)^2)
}

# Finding the training MSE for each K
trainMSE <- c()
for(i in 1:length(K)){
  est <- knn.reg(train = Train_rb[,2:4], test = Train_rb[2:4], y = Train_rb$rf_t10, k = K[i])
  trainMSE[i] <- mean((est$pred - Train_rb$rf_t10)^2)
}

# Plotting the test MSEs
plot(K, testMSE, xlab = "K", ylab = "Testing MSE", main = "Testing MSE as a function of K", type = "l", col = "blue4")
# Plotting the training MSEs
plot(K, trainMSE, xlab = "K", ylab = "Training MSE", main = "Training MSE as a function of K", type = "l", col = "red4")

# Finding the K value that yields the lowest training MSE
K[which.min(trainMSE)]
# Finding the K value that yields the lowest test MSE
K[which.min(testMSE)]
```

## Finding Training and Test estimates
```{r}
# Performing KNN regression with K = 1000
Train_est <- knn.reg(train = Train_rb[,2:4], test = Train_rb[2:4], y = Train_rb$rf_t10, k = 1000)$pred

Test_est <- knn.reg(train = Train_rb[,2:4], test = Test_rb[2:4], y = Train_rb$rf_t10, k = 1000)$pred

# Finding the in-sample and out-of-sample correlations
cor(Test_est, Test_rb$rf_t10)
cor(Train_est, Train_rb$rf_t10)
```

The correlation between the actual training response and the predicted training response is 0.083, while the correlation between the predicted test response and the actual test response is 0.029.



##2.5 Ridge and LASSO

```{r }
library(glmnet)
library(tidyverse)

final_project <- read_csv("data/final_project-1.csv")
final_project <- final_project %>% select(Asset_1:Asset_3)
Asset_1 <- final_project %>% select(Asset_1)

```


```{r}
#final solution for calculating backward returns

bw_full <- read.csv("final_project-1.csv")
time.horizons = c(3,10,30,60,120,180,240,360,480,600,720,960,1200,1440)

for (time in time.horizons) {
  bw_full = mutate(bw_full, "Asset_1_BRet_{time}" := (bw_full$Asset_1 - ifelse(X > (time-1), lag(bw_full$Asset_1, n=time), bw_full$Asset_1[1]))/ifelse(X > (time-1), lag(bw_full$Asset_1, n=time), bw_full$Asset_1[1]))
  bw_full = mutate(bw_full, "Asset_2_BRet_{time}" := (bw_full$Asset_2 - ifelse(X > (time-1), lag(bw_full$Asset_2, n=time), bw_full$Asset_2[1]))/ifelse(X > (time-1), lag(bw_full$Asset_2, n=time), bw_full$Asset_2[1]))
  bw_full = mutate(bw_full, "Asset_3_BRet_{time}" := (bw_full$Asset_3 - ifelse(X > (time-1), lag(bw_full$Asset_3, n=time), bw_full$Asset_3[1]))/ifelse(X > (time-1), lag(bw_full$Asset_3, n=time), bw_full$Asset_3[1]))
}

bw_full <- bw_full[-c(1:4)]


```

The backward returns in required time horizons are included in bw_full file. 

#Ridge

``` {r }
#Calculate forward returns and add the new variable
Asset_1_lead <- lead(Asset_1, n=10, default=tail(Asset_1, 1))
Asset_1_BRet_10_forward <- (Asset_1_lead - Asset_1) / Asset_1
colnames(Asset_1_BRet_10_forward) <- c("Asset_1_BRet_10_forward")
bw_full <- cbind(bw_full, Asset_1_BRet_10_forward)


train_size <- floor(nrow(bw_full) * 0.7)

data_ridge_train <- bw_full[1: train_size,]
data_ridge_test <- bw_full[-(1:train_size),]

set.seed(42)
train_id <- sample(1:nrow(bw_full), size = trunc(nrow(bw_full)))

X <- model.matrix(Asset_1_BRet_10_forward ~ ., data = bw_full)[, -1]
X_train <- X[1: train_size,]
X_test <- X[-(1: train_size),]

grid = 10^seq(10, -2, length = 100)
ridge.mod = glmnet(x = X_train, y = data_ridge_train$Asset_1_BRet_10_forward, alpha = 0, lambda = grid)
plot(ridge.mod, xvar = "lambda",  label = TRUE )

set.seed(1)
cv.out = cv.glmnet(x = X_train, y = data_ridge_train$Asset_1_BRet_10_forward, alpha = 0, lambda = grid)
bestlam = cv.out$lambda.min
bestlam

ridge.pred_train = predict(ridge.mod, s = bestlam, newx = X_train)
mean((ridge.pred_train - data_ridge_train$Asset_1_BRet_10_forward)^2)

ridge.pred_test = predict(ridge.mod, s = bestlam, newx = X_test)
mean((ridge.pred_test - data_ridge_test$Asset_1_BRet_10_forward)^2)

pred_ridge <- predict(ridge.mod, s = bestlam, newx =  X)



sprintf("Forward return for rf (t, 10) of Asset 1 are included in pred_ridge. The best tuning parameter should be %s", bestlam)

#In-sample correlation
cor(as.matrix(cbind(ridge.pred_train, data_ridge_train$Asset_1_BRet_10_forward)))

sprintf("The in-sample correlation is %s",
cor(as.matrix(cbind(ridge.pred_train, data_ridge_train$Asset_1_BRet_10_forward)))[[2,1]])

#Out-of-sample correlation
cor(as.matrix(cbind(ridge.pred_test, data_ridge_test$Asset_1_BRet_10_forward)))

sprintf("The out-of-sample correlation is %s",
cor(as.matrix(cbind(ridge.pred_test, data_ridge_test$Asset_1_BRet_10_forward)))[[2,1]])


```

# 2.6 Principle component regression (PCR)

## Task

Run PCR with the same features and response as in Section 2.5. Use the first 70% data as training data and the last 30% data as validation data. Use the validation MSE to seek the optimal number of principal components to include in PCR and generate the corresponding prediction for the whole year. Report the in-sample and out-of-sample correlation between your prediction and true response.

## Load required libraries
```{r}
library(pls)
```


## Calculate backward returns
```{r, message=F, warning=F}
data_pcr <- read_csv("data/final_project-1.csv")
colnames(data_pcr) <- c("X", "Asset_1", "Asset_2", "Asset_3")

time.horizons = c(3,10,30,60,120,180,240,360,480,600,720,960,1200,1440)

for (time in time.horizons) {
  data_pcr = mutate(data_pcr, "Asset_1_BRet_{time}" := (data_pcr$Asset_1 - ifelse(X > (time-1), lag(data_pcr$Asset_1, n=time), data_pcr$Asset_1[1]))/ifelse(X > (time-1), lag(data_pcr$Asset_1, n=time), data_pcr$Asset_1[1]))
  data_pcr = mutate(data_pcr, "Asset_2_BRet_{time}" := (data_pcr$Asset_2 - ifelse(X > (time-1), lag(data_pcr$Asset_2, n=time), data_pcr$Asset_2[1]))/ifelse(X > (time-1), lag(data_pcr$Asset_2, n=time), data_pcr$Asset_2[1]))
  data_pcr = mutate(data_pcr, "Asset_3_BRet_{time}" := (data_pcr$Asset_3 - ifelse(X > (time-1), lag(data_pcr$Asset_3, n=time), data_pcr$Asset_3[1]))/ifelse(X > (time-1), lag(data_pcr$Asset_3, n=time), data_pcr$Asset_3[1]))
}
```

## Calculate response
```{r}
Asset_1 <- data_pcr %>% select(Asset_1)
Asset_1_lead <- lead(Asset_1, n=10, default=tail(Asset_1, 1))
Asset_1_HRet_10 <- (Asset_1_lead - Asset_1) / Asset_1
colnames(Asset_1_HRet_10) <- c("Asset_1_HRet_10")
data_pcr <- cbind(data_pcr, Asset_1_HRet_10)
```

## Prepare data
```{r}
# remove index column and underlying asset prices
data_pcr <- data_pcr[,-c(1:4)]

# using first 70% as train data
train_id <- 1:floor(nrow(data_pcr) * 0.7)
```

## Train Principal Component Regression (PCR) Model
```{r}
# train model without restrictions
returnPCR <- pcr(Asset_1_HRet_10 ~ ., data = data_pcr, subset = train_id, scale = T, validation = "CV")

# evaluate model
summary(returnPCR)
validationplot(returnPCR, val.type = "MSEP", legendpos = "topright")
```

We find that 11 components collectively explain 95% of variance in response variable and that we get the lowest mean squared error of prediction (from 10-fold cross validation, adjusted) when using most or all of the 42 components. We can also test different values for ncomps with the training/test split we defined earlier:

```{r}
ncompss = 1:42
cors <- vector(length = length(ncompss))
for (i in 1:length(ncompss)) {
  returnPCR.pred.test <- predict(returnPCR, data_pcr[-train_id, names(data_pcr) != 'Asset_1_HRet_10'], ncomp = ncompss[i])
  cors[i] <- cor(returnPCR.pred.test, data_pcr[-train_id, names(data_pcr) == 'Asset_1_HRet_10'])
}
paste("Highest out-of-sample correlation for PCR:", round(max(cors),4), "(for", which.max(cors), "components)")
```

Based on the CV and the test error - and mindful of the computational cost of our prediction - we decided to go with a relatively simple principal component regression model that used six components. 

## Evaluate Model
```{r}
# predict train data using PCR with 22 principal components
returnPCR.pred.train <- predict(returnPCR, data_pcr[train_id, names(data_pcr) != 'Asset_1_HRet_10'], ncomp = 6)

# Calculate in-sample correlation
PCR.cor.train <- cor(returnPCR.pred.train, data_pcr[train_id, names(data_pcr) == 'Asset_1_HRet_10'])
paste("In-sample correlation for PCR:", round(PCR.cor.train,4))

# predict test data using PCR with 22 principal components
returnPCR.pred.test <- predict(returnPCR, data_pcr[-train_id, names(data_pcr) != 'Asset_1_HRet_10'], ncomp = 6)

# Calculate out-of-sample correlation
PCR.cor.test <- cor(returnPCR.pred.test, data_pcr[-train_id, names(data_pcr) == 'Asset_1_HRet_10'])
paste("Out-of-sample correlation for PCR:", round(PCR.cor.test,4))
```


